{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, roc_auc_score \n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def status_map(status):\n",
    "    if 'no_relapse' in status or 'NoRelapse' in status:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "status_list =['relapse', 'no_relapse', \n",
    "              'test1relapse', 'test1no_relapse', \n",
    "              'test2relapse', 'test2no_relapse', \n",
    "              'NewTest1_Relapse', 'NewTest1_NoRelapse', \n",
    "              'NewTest2_Relapse', 'NewTest2_NoRelapse']\n",
    "\n",
    "class BcData:\n",
    "    def __init__(self):\n",
    "        self.data = pd.read_csv(\"data/data_good.csv\")\n",
    "        self.total = pd.read_csv(\"data/Total_old.csv\", names=[\"gsm\", \"status\"])\n",
    "        self._drop_grey()\n",
    "        self._log_table()\n",
    "\n",
    "    # Drop grey columns\n",
    "    def _drop_grey(self):\n",
    "        self.gsm_series = self.total[self.total.status.isin(status_list)].gsm\n",
    "        new_cols = pd.Series([\"GeneSymbol\"]).append(self.gsm_series)\n",
    "\n",
    "        self.total = self.total[self.total.gsm.isin(self.gsm_series)]\n",
    "        self.data = self.data.filter(items=new_cols)\n",
    "\n",
    "    # Group rows by gene leaving max median row\n",
    "    def _groupby_gene(self):\n",
    "        return self.data\\\n",
    "            .groupby(\"GeneSymbol\", as_index=False, sort=False)\\\n",
    "            .apply(lambda f: f.loc[f.median(axis=1).idxmax()])\n",
    "\n",
    "    def _log_table(self):\n",
    "        index = self.data.iloc[:, 0]\n",
    "        self.data = np.log2(self.data.iloc[:, 1:])\n",
    "        self.data.insert(0, \"GeneSymbol\", index)\n",
    "\n",
    "    def _get_status(self):\n",
    "        return self.total.status.map(status_map)\n",
    "\n",
    "    # Drop rows with quantile less than threshold (values = {7, 8, 9})\n",
    "    def filter_percentile(self, quantile=1, threshold=9):\n",
    "        q = self.data.quantile(q=quantile, axis=1)\n",
    "        index = q[q >= threshold].index.values\n",
    "        self.data = self.data.loc[index, :]\n",
    "\n",
    "    # Drop rows with max/min diff less than threshold (values = {1.5, 2})\n",
    "    def filter_diff_percentile(self, qmax=1, qmin=0, threshold=2):\n",
    "        threshold = np.log2(threshold)\n",
    "        max = self.data.quantile(q=qmax, axis=1)\n",
    "        min = self.data.quantile(q=qmin, axis=1)\n",
    "        index = max[max - min >= threshold].index.values\n",
    "        self.data = self.data.loc[index, :]\n",
    "\n",
    "    # Final mutation\n",
    "    def group_data(self):\n",
    "        grouped = self._groupby_gene().T\n",
    "        self.data = grouped.rename(columns=grouped.iloc[0]).drop(grouped.index[0])\n",
    "        \n",
    "    # values = {0, 1, 2, 3, 4}\n",
    "    def train_test_split(self, test_fold_number=0):\n",
    "        test_status = status_list[test_fold_number:test_fold_number+2]\n",
    "        total_test = self.total[self.total.status.isin(test_status)]\n",
    "        total_train = self.total[~self.total.status.isin(test_status)]\n",
    "        \n",
    "        X_test = self.data.loc[total_test.gsm]\n",
    "        X_train = self.data.loc[total_train.gsm]\n",
    "        y_test = total_test.status.map(status_map)\n",
    "        y_train = total_train.status.map(status_map)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAT1</th>\n",
       "      <th>GAPDH</th>\n",
       "      <th>ACTB</th>\n",
       "      <th>PRPF8</th>\n",
       "      <th>GDI2</th>\n",
       "      <th>RPL21</th>\n",
       "      <th>EIF3F</th>\n",
       "      <th>RPS5</th>\n",
       "      <th>RPL10A</th>\n",
       "      <th>RPL17</th>\n",
       "      <th>...</th>\n",
       "      <th>TMEM135</th>\n",
       "      <th>LASS2</th>\n",
       "      <th>MRPL17</th>\n",
       "      <th>SLC27A3</th>\n",
       "      <th>ACTR10</th>\n",
       "      <th>LRRC59</th>\n",
       "      <th>ISYNA1</th>\n",
       "      <th>UBQLN4</th>\n",
       "      <th>SH3BP4</th>\n",
       "      <th>KCNE4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM441628</th>\n",
       "      <td>10.1189</td>\n",
       "      <td>12.4899</td>\n",
       "      <td>12.3241</td>\n",
       "      <td>8.12817</td>\n",
       "      <td>10.2657</td>\n",
       "      <td>12.6354</td>\n",
       "      <td>10.2893</td>\n",
       "      <td>12.3643</td>\n",
       "      <td>12.0118</td>\n",
       "      <td>12.9817</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4559</td>\n",
       "      <td>10.3364</td>\n",
       "      <td>9.39708</td>\n",
       "      <td>8.1336</td>\n",
       "      <td>10.2042</td>\n",
       "      <td>9.54129</td>\n",
       "      <td>7.41549</td>\n",
       "      <td>6.92487</td>\n",
       "      <td>9.61767</td>\n",
       "      <td>5.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM441629</th>\n",
       "      <td>9.45188</td>\n",
       "      <td>11.89</td>\n",
       "      <td>11.1485</td>\n",
       "      <td>9.80213</td>\n",
       "      <td>8.99319</td>\n",
       "      <td>11.964</td>\n",
       "      <td>10.0725</td>\n",
       "      <td>11.6801</td>\n",
       "      <td>11.5113</td>\n",
       "      <td>12.2222</td>\n",
       "      <td>...</td>\n",
       "      <td>7.36097</td>\n",
       "      <td>10.5038</td>\n",
       "      <td>8.98289</td>\n",
       "      <td>7.57143</td>\n",
       "      <td>9.32403</td>\n",
       "      <td>10.963</td>\n",
       "      <td>7.00116</td>\n",
       "      <td>7.44613</td>\n",
       "      <td>7.91139</td>\n",
       "      <td>8.47747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM441643</th>\n",
       "      <td>8.3548</td>\n",
       "      <td>12.8534</td>\n",
       "      <td>12.2794</td>\n",
       "      <td>9.26371</td>\n",
       "      <td>9.68239</td>\n",
       "      <td>12.0003</td>\n",
       "      <td>10.9454</td>\n",
       "      <td>12.4005</td>\n",
       "      <td>11.3411</td>\n",
       "      <td>12.486</td>\n",
       "      <td>...</td>\n",
       "      <td>6.02202</td>\n",
       "      <td>10.8261</td>\n",
       "      <td>9.55747</td>\n",
       "      <td>7.52877</td>\n",
       "      <td>9.72201</td>\n",
       "      <td>9.55876</td>\n",
       "      <td>8.22317</td>\n",
       "      <td>7.19559</td>\n",
       "      <td>9.03323</td>\n",
       "      <td>7.93546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM441644</th>\n",
       "      <td>10.6103</td>\n",
       "      <td>13.2989</td>\n",
       "      <td>12.1458</td>\n",
       "      <td>8.18223</td>\n",
       "      <td>10.006</td>\n",
       "      <td>12.4623</td>\n",
       "      <td>10.0924</td>\n",
       "      <td>12.8321</td>\n",
       "      <td>11.9007</td>\n",
       "      <td>12.7933</td>\n",
       "      <td>...</td>\n",
       "      <td>7.59432</td>\n",
       "      <td>9.8764</td>\n",
       "      <td>9.36144</td>\n",
       "      <td>5.99566</td>\n",
       "      <td>10.2223</td>\n",
       "      <td>9.32937</td>\n",
       "      <td>7.16173</td>\n",
       "      <td>6.67637</td>\n",
       "      <td>8.4719</td>\n",
       "      <td>5.65332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM441657</th>\n",
       "      <td>10.7411</td>\n",
       "      <td>12.6399</td>\n",
       "      <td>12.1225</td>\n",
       "      <td>8.69317</td>\n",
       "      <td>9.86313</td>\n",
       "      <td>12.6431</td>\n",
       "      <td>10.5805</td>\n",
       "      <td>12.3452</td>\n",
       "      <td>12.3039</td>\n",
       "      <td>12.8404</td>\n",
       "      <td>...</td>\n",
       "      <td>8.68881</td>\n",
       "      <td>10.9884</td>\n",
       "      <td>8.70488</td>\n",
       "      <td>6.36779</td>\n",
       "      <td>9.8479</td>\n",
       "      <td>9.67044</td>\n",
       "      <td>6.74766</td>\n",
       "      <td>6.58517</td>\n",
       "      <td>10.1066</td>\n",
       "      <td>6.98088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM79256</th>\n",
       "      <td>8.951</td>\n",
       "      <td>11.7398</td>\n",
       "      <td>12.2444</td>\n",
       "      <td>9.204</td>\n",
       "      <td>8.56978</td>\n",
       "      <td>12.2456</td>\n",
       "      <td>10.312</td>\n",
       "      <td>11.9125</td>\n",
       "      <td>11.9337</td>\n",
       "      <td>12.5949</td>\n",
       "      <td>...</td>\n",
       "      <td>6.55152</td>\n",
       "      <td>10.3828</td>\n",
       "      <td>7.52995</td>\n",
       "      <td>6.86207</td>\n",
       "      <td>9.2944</td>\n",
       "      <td>8.40215</td>\n",
       "      <td>7.08712</td>\n",
       "      <td>7.0161</td>\n",
       "      <td>9.45736</td>\n",
       "      <td>5.83043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM79307</th>\n",
       "      <td>8.63579</td>\n",
       "      <td>11.874</td>\n",
       "      <td>12.7701</td>\n",
       "      <td>8.5807</td>\n",
       "      <td>8.93809</td>\n",
       "      <td>11.966</td>\n",
       "      <td>10.0928</td>\n",
       "      <td>11.523</td>\n",
       "      <td>11.8744</td>\n",
       "      <td>12.4581</td>\n",
       "      <td>...</td>\n",
       "      <td>7.40512</td>\n",
       "      <td>10.2444</td>\n",
       "      <td>7.59653</td>\n",
       "      <td>7.25855</td>\n",
       "      <td>9.25592</td>\n",
       "      <td>8.7403</td>\n",
       "      <td>7.90226</td>\n",
       "      <td>7.1078</td>\n",
       "      <td>9.03438</td>\n",
       "      <td>6.49406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM79194</th>\n",
       "      <td>8.23052</td>\n",
       "      <td>11.6573</td>\n",
       "      <td>12.8212</td>\n",
       "      <td>9.41964</td>\n",
       "      <td>8.54347</td>\n",
       "      <td>11.4439</td>\n",
       "      <td>9.82976</td>\n",
       "      <td>11.2178</td>\n",
       "      <td>10.87</td>\n",
       "      <td>12.0338</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00599</td>\n",
       "      <td>10.3581</td>\n",
       "      <td>7.38679</td>\n",
       "      <td>7.42136</td>\n",
       "      <td>8.55693</td>\n",
       "      <td>8.91121</td>\n",
       "      <td>7.54922</td>\n",
       "      <td>6.41859</td>\n",
       "      <td>9.14434</td>\n",
       "      <td>7.35013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM79179</th>\n",
       "      <td>8.70025</td>\n",
       "      <td>12.5266</td>\n",
       "      <td>12.5553</td>\n",
       "      <td>8.44396</td>\n",
       "      <td>8.8949</td>\n",
       "      <td>12.1446</td>\n",
       "      <td>10.2204</td>\n",
       "      <td>11.1942</td>\n",
       "      <td>12.0194</td>\n",
       "      <td>12.0932</td>\n",
       "      <td>...</td>\n",
       "      <td>6.62486</td>\n",
       "      <td>10.6735</td>\n",
       "      <td>8.18407</td>\n",
       "      <td>7.44046</td>\n",
       "      <td>9.39059</td>\n",
       "      <td>8.90865</td>\n",
       "      <td>7.00536</td>\n",
       "      <td>7.23688</td>\n",
       "      <td>10.008</td>\n",
       "      <td>7.48382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM79182</th>\n",
       "      <td>9.35032</td>\n",
       "      <td>11.8844</td>\n",
       "      <td>12.1839</td>\n",
       "      <td>9.5628</td>\n",
       "      <td>8.56547</td>\n",
       "      <td>12.42</td>\n",
       "      <td>10.7255</td>\n",
       "      <td>11.9486</td>\n",
       "      <td>12.1248</td>\n",
       "      <td>12.714</td>\n",
       "      <td>...</td>\n",
       "      <td>7.34798</td>\n",
       "      <td>9.39389</td>\n",
       "      <td>7.42398</td>\n",
       "      <td>7.54725</td>\n",
       "      <td>9.37103</td>\n",
       "      <td>8.30605</td>\n",
       "      <td>6.94889</td>\n",
       "      <td>7.15277</td>\n",
       "      <td>8.68716</td>\n",
       "      <td>5.52577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows Ã— 3849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             STAT1    GAPDH     ACTB    PRPF8     GDI2    RPL21    EIF3F  \\\n",
       "GSM441628  10.1189  12.4899  12.3241  8.12817  10.2657  12.6354  10.2893   \n",
       "GSM441629  9.45188    11.89  11.1485  9.80213  8.99319   11.964  10.0725   \n",
       "GSM441643   8.3548  12.8534  12.2794  9.26371  9.68239  12.0003  10.9454   \n",
       "GSM441644  10.6103  13.2989  12.1458  8.18223   10.006  12.4623  10.0924   \n",
       "GSM441657  10.7411  12.6399  12.1225  8.69317  9.86313  12.6431  10.5805   \n",
       "...            ...      ...      ...      ...      ...      ...      ...   \n",
       "GSM79256     8.951  11.7398  12.2444    9.204  8.56978  12.2456   10.312   \n",
       "GSM79307   8.63579   11.874  12.7701   8.5807  8.93809   11.966  10.0928   \n",
       "GSM79194   8.23052  11.6573  12.8212  9.41964  8.54347  11.4439  9.82976   \n",
       "GSM79179   8.70025  12.5266  12.5553  8.44396   8.8949  12.1446  10.2204   \n",
       "GSM79182   9.35032  11.8844  12.1839   9.5628  8.56547    12.42  10.7255   \n",
       "\n",
       "              RPS5   RPL10A    RPL17  ...  TMEM135    LASS2   MRPL17  SLC27A3  \\\n",
       "GSM441628  12.3643  12.0118  12.9817  ...   7.4559  10.3364  9.39708   8.1336   \n",
       "GSM441629  11.6801  11.5113  12.2222  ...  7.36097  10.5038  8.98289  7.57143   \n",
       "GSM441643  12.4005  11.3411   12.486  ...  6.02202  10.8261  9.55747  7.52877   \n",
       "GSM441644  12.8321  11.9007  12.7933  ...  7.59432   9.8764  9.36144  5.99566   \n",
       "GSM441657  12.3452  12.3039  12.8404  ...  8.68881  10.9884  8.70488  6.36779   \n",
       "...            ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "GSM79256   11.9125  11.9337  12.5949  ...  6.55152  10.3828  7.52995  6.86207   \n",
       "GSM79307    11.523  11.8744  12.4581  ...  7.40512  10.2444  7.59653  7.25855   \n",
       "GSM79194   11.2178    10.87  12.0338  ...  6.00599  10.3581  7.38679  7.42136   \n",
       "GSM79179   11.1942  12.0194  12.0932  ...  6.62486  10.6735  8.18407  7.44046   \n",
       "GSM79182   11.9486  12.1248   12.714  ...  7.34798  9.39389  7.42398  7.54725   \n",
       "\n",
       "            ACTR10   LRRC59   ISYNA1   UBQLN4   SH3BP4    KCNE4  \n",
       "GSM441628  10.2042  9.54129  7.41549  6.92487  9.61767   5.0048  \n",
       "GSM441629  9.32403   10.963  7.00116  7.44613  7.91139  8.47747  \n",
       "GSM441643  9.72201  9.55876  8.22317  7.19559  9.03323  7.93546  \n",
       "GSM441644  10.2223  9.32937  7.16173  6.67637   8.4719  5.65332  \n",
       "GSM441657   9.8479  9.67044  6.74766  6.58517  10.1066  6.98088  \n",
       "...            ...      ...      ...      ...      ...      ...  \n",
       "GSM79256    9.2944  8.40215  7.08712   7.0161  9.45736  5.83043  \n",
       "GSM79307   9.25592   8.7403  7.90226   7.1078  9.03438  6.49406  \n",
       "GSM79194   8.55693  8.91121  7.54922  6.41859  9.14434  7.35013  \n",
       "GSM79179   9.39059  8.90865  7.00536  7.23688   10.008  7.48382  \n",
       "GSM79182   9.37103  8.30605  6.94889  7.15277  8.68716  5.52577  \n",
       "\n",
       "[748 rows x 3849 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc = BcData()\n",
    "bc.filter_diff_percentile(qmax=0.75, qmin=0.25, threshold=1.5)\n",
    "bc.filter_percentile(quantile=0.75, threshold=7)\n",
    "bc.group_data()\n",
    "bc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity = 0.5833333333333334 auc = 0.6871890547263683\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = bc.train_test_split(test_fold_number=2)\n",
    "\n",
    "# Set dual = True if number of features > number of examples and vice versa\n",
    "# clf = svm.LinearSVC(penalty='l1', dual=False, C=1, max_iter=100000)\n",
    "clf  = svm.SVC(kernel=\"linear\", C=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"sensitivity = {} auc = {}\".format(recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 8 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 9 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 15 step: sensitivity = 0.75 auc = 0.7854477611940298\n",
      "For 16 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 17 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 18 step: sensitivity = 0.75 auc = 0.7779850746268656\n",
      "For 19 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 20 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 21 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 22 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 32 step: sensitivity = 0.6666666666666666 auc = 0.7587064676616915\n",
      "For 160 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 193 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 194 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 195 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 196 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 197 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 198 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 238 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 495 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 496 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 497 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 499 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 500 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 589 step: sensitivity = 0.6666666666666666 auc = 0.7736318407960199\n",
      "For 804 step: sensitivity = 0.6666666666666666 auc = 0.691542288557214\n",
      "For 805 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 819 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 820 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 821 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 1515 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 1516 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 1517 step: sensitivity = 0.6666666666666666 auc = 0.6542288557213931\n",
      "For 1518 step: sensitivity = 0.6666666666666666 auc = 0.6616915422885572\n",
      "For 1519 step: sensitivity = 0.6666666666666666 auc = 0.6542288557213931\n",
      "For 1520 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 1521 step: sensitivity = 0.6666666666666666 auc = 0.691542288557214\n",
      "For 1522 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 1523 step: sensitivity = 0.6666666666666666 auc = 0.6766169154228855\n",
      "For 1524 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 1525 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 1526 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 1527 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 1528 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 1529 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 1530 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 1531 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 1820 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 1822 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 1823 step: sensitivity = 0.6666666666666666 auc = 0.7512437810945273\n",
      "For 1826 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 1827 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 1908 step: sensitivity = 0.8333333333333334 auc = 0.6629353233830846\n",
      "For 1909 step: sensitivity = 0.8333333333333334 auc = 0.6927860696517414\n",
      "For 1910 step: sensitivity = 0.8333333333333334 auc = 0.7300995024875623\n",
      "For 1911 step: sensitivity = 0.75 auc = 0.6735074626865671\n",
      "For 1912 step: sensitivity = 0.75 auc = 0.6585820895522388\n",
      "For 1913 step: sensitivity = 0.75 auc = 0.6585820895522388\n",
      "For 1914 step: sensitivity = 0.75 auc = 0.6735074626865671\n",
      "For 1915 step: sensitivity = 0.8333333333333334 auc = 0.6853233830845772\n",
      "For 1916 step: sensitivity = 0.8333333333333334 auc = 0.6927860696517414\n",
      "For 1917 step: sensitivity = 0.8333333333333334 auc = 0.7002487562189056\n",
      "For 1918 step: sensitivity = 0.75 auc = 0.666044776119403\n",
      "For 1919 step: sensitivity = 0.75 auc = 0.6511194029850746\n",
      "For 1920 step: sensitivity = 0.75 auc = 0.6585820895522388\n",
      "For 1922 step: sensitivity = 0.75 auc = 0.6809701492537313\n",
      "For 1923 step: sensitivity = 0.75 auc = 0.6735074626865671\n",
      "For 1924 step: sensitivity = 0.8333333333333334 auc = 0.677860696517413\n",
      "For 1925 step: sensitivity = 0.75 auc = 0.6809701492537313\n",
      "For 1926 step: sensitivity = 0.75 auc = 0.6735074626865671\n",
      "For 1927 step: sensitivity = 0.75 auc = 0.6735074626865671\n",
      "For 1928 step: sensitivity = 0.75 auc = 0.666044776119403\n",
      "For 1929 step: sensitivity = 0.75 auc = 0.6585820895522388\n",
      "For 1932 step: sensitivity = 0.75 auc = 0.6884328358208955\n",
      "For 1933 step: sensitivity = 0.8333333333333334 auc = 0.677860696517413\n",
      "For 1934 step: sensitivity = 0.8333333333333334 auc = 0.7300995024875623\n",
      "For 1935 step: sensitivity = 0.75 auc = 0.6884328358208955\n",
      "For 1936 step: sensitivity = 0.6666666666666666 auc = 0.6542288557213931\n",
      "For 1938 step: sensitivity = 0.75 auc = 0.666044776119403\n",
      "For 1939 step: sensitivity = 0.75 auc = 0.6585820895522388\n",
      "For 1940 step: sensitivity = 0.6666666666666666 auc = 0.6542288557213931\n",
      "For 1942 step: sensitivity = 0.6666666666666666 auc = 0.6616915422885572\n",
      "For 1943 step: sensitivity = 0.6666666666666666 auc = 0.691542288557214\n",
      "For 1944 step: sensitivity = 0.75 auc = 0.7257462686567164\n",
      "For 1945 step: sensitivity = 0.75 auc = 0.6884328358208955\n",
      "For 1946 step: sensitivity = 0.75 auc = 0.6809701492537313\n",
      "For 1947 step: sensitivity = 0.75 auc = 0.6958955223880599\n",
      "For 1948 step: sensitivity = 0.75 auc = 0.7182835820895522\n",
      "For 1949 step: sensitivity = 0.75 auc = 0.7033582089552239\n",
      "For 1950 step: sensitivity = 0.75 auc = 0.7033582089552239\n",
      "For 1951 step: sensitivity = 0.75 auc = 0.7182835820895522\n",
      "For 1952 step: sensitivity = 0.75 auc = 0.7033582089552239\n",
      "For 1953 step: sensitivity = 0.75 auc = 0.7033582089552239\n",
      "For 1954 step: sensitivity = 0.75 auc = 0.6884328358208955\n",
      "For 1955 step: sensitivity = 0.75 auc = 0.6809701492537313\n",
      "For 1956 step: sensitivity = 0.75 auc = 0.6809701492537313\n",
      "For 1957 step: sensitivity = 0.75 auc = 0.6585820895522388\n",
      "For 1961 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 1964 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 1968 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 1969 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 1970 step: sensitivity = 0.75 auc = 0.7630597014925374\n",
      "For 1971 step: sensitivity = 0.75 auc = 0.7705223880597016\n",
      "For 1975 step: sensitivity = 0.6666666666666666 auc = 0.7587064676616915\n",
      "For 1976 step: sensitivity = 0.6666666666666666 auc = 0.7587064676616915\n",
      "For 1978 step: sensitivity = 0.6666666666666666 auc = 0.7587064676616915\n",
      "For 1979 step: sensitivity = 0.75 auc = 0.7705223880597016\n",
      "For 1980 step: sensitivity = 0.6666666666666666 auc = 0.7587064676616915\n",
      "For 1989 step: sensitivity = 0.6666666666666666 auc = 0.7512437810945273\n",
      "For 1994 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 1995 step: sensitivity = 0.6666666666666666 auc = 0.7512437810945273\n",
      "For 1996 step: sensitivity = 0.75 auc = 0.7854477611940298\n",
      "For 1998 step: sensitivity = 0.6666666666666666 auc = 0.7587064676616915\n",
      "For 1999 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2001 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 2123 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 2124 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2125 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2126 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n",
      "For 2127 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 2128 step: sensitivity = 0.6666666666666666 auc = 0.736318407960199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2129 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 2130 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 2131 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2132 step: sensitivity = 0.6666666666666666 auc = 0.7512437810945273\n",
      "For 2133 step: sensitivity = 0.6666666666666666 auc = 0.7512437810945273\n",
      "For 2186 step: sensitivity = 0.6666666666666666 auc = 0.7661691542288557\n",
      "For 2199 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 2201 step: sensitivity = 0.75 auc = 0.8078358208955224\n",
      "For 2206 step: sensitivity = 0.6666666666666666 auc = 0.7661691542288557\n",
      "For 2348 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 2349 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2368 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 2698 step: sensitivity = 0.75 auc = 0.7555970149253731\n",
      "For 2699 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 2861 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 2868 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 2869 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 2870 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2871 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2872 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2873 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 2874 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 2875 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 2876 step: sensitivity = 0.6666666666666666 auc = 0.7437810945273631\n",
      "For 2878 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 3056 step: sensitivity = 0.75 auc = 0.7257462686567164\n",
      "For 3057 step: sensitivity = 0.6666666666666666 auc = 0.691542288557214\n",
      "For 3058 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 3059 step: sensitivity = 0.6666666666666666 auc = 0.691542288557214\n",
      "For 3060 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 3061 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 3065 step: sensitivity = 0.6666666666666666 auc = 0.7288557213930348\n",
      "For 3067 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 3075 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 3079 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 3209 step: sensitivity = 0.6666666666666666 auc = 0.7213930348258706\n",
      "For 3210 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 3211 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 3212 step: sensitivity = 0.75 auc = 0.7630597014925374\n",
      "For 3213 step: sensitivity = 0.75 auc = 0.7779850746268656\n",
      "For 3214 step: sensitivity = 0.75 auc = 0.7332089552238806\n",
      "For 3215 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 3216 step: sensitivity = 0.6666666666666666 auc = 0.7139303482587064\n",
      "For 3217 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 3218 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 3219 step: sensitivity = 0.6666666666666666 auc = 0.6691542288557213\n",
      "For 3220 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 3221 step: sensitivity = 0.6666666666666666 auc = 0.6766169154228855\n",
      "For 3222 step: sensitivity = 0.6666666666666666 auc = 0.6990049751243781\n",
      "For 3223 step: sensitivity = 0.6666666666666666 auc = 0.691542288557214\n",
      "For 3224 step: sensitivity = 0.6666666666666666 auc = 0.6840796019900497\n",
      "For 3225 step: sensitivity = 0.6666666666666666 auc = 0.691542288557214\n",
      "For 3226 step: sensitivity = 0.75 auc = 0.710820895522388\n",
      "For 3228 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 3229 step: sensitivity = 0.6666666666666666 auc = 0.7064676616915422\n",
      "For 3419 step: sensitivity = 0.6666666666666666 auc = 0.781094527363184\n",
      "For 3420 step: sensitivity = 0.75 auc = 0.8078358208955224\n"
     ]
    }
   ],
   "source": [
    "step = 50\n",
    "total = len(X_train.columns)\n",
    "\n",
    "# for i in range(0, total, step):\n",
    "for i in range(total):\n",
    "    if i + step >= total:\n",
    "        break\n",
    "        \n",
    "    clf  = svm.SVC(kernel=\"linear\", C=1)\n",
    "    clf.fit(X_train.iloc[:, i:i+step], y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test.iloc[:, i:i+step])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    if (recall > 0.6 and auc > 0.65):\n",
    "        print(\"For {} step: sensitivity = {} auc = {}\".format(i, recall, auc))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (bc_classification)",
   "language": "python",
   "name": "pycharm-450a18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
